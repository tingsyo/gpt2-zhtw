{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d9d0128",
   "metadata": {},
   "source": [
    "# Derive Embedding with Sentence-Transformers\n",
    "\n",
    "In this notebook we explored a few ways to map a sentence to a vector.\n",
    "\n",
    "\n",
    "## References for Sentence Embedding\n",
    "- [Document Embedding Techniques - 2019](https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d)\n",
    "    - Classic techniques\n",
    "        * Bag-of-words\n",
    "        * Latent Dirichlet Allocation (LDA)\n",
    "    - Unsupervised document embedding techniques\n",
    "        * n-gram embeddings\n",
    "        * Averaging word embeddings\n",
    "        * Sent2Vec\n",
    "        * Paragraph vectors (doc2vec)\n",
    "        * Doc2VecC\n",
    "        * Skip-thought vectors\n",
    "        * FastSent\n",
    "        * Quick-thought vectors\n",
    "        * Word Mover’s Embedding (WME)\n",
    "        * Sentence-BERT (SBERT)\n",
    "    - Supervised document embedding techniques\n",
    "        * Learning document embeddings from labeled data\n",
    "        * Task-specific supervised document embeddings\n",
    "        * — GPT\n",
    "        * — Deep Semantic Similarity Model (DSSM)\n",
    "        * Jointly learning sentence representations\n",
    "        * — Universal Sentence Encoder\n",
    "        * — GenSen\n",
    "- [Top 4 Sentence Embedding Techniques using Python! - 2020](https://www.analyticsvidhya.com/blog/2020/08/top-4-sentence-embedding-techniques-using-python/)\n",
    "    + Doc2Vec\n",
    "    + SentenceBERT\n",
    "    + InferSent\n",
    "    + Universal Sentence Encoder\n",
    "\n",
    "## Pre-trained Sentence Transformers\n",
    "- [Github](https://github.com/UKPLab/sentence-transformers)\n",
    "- [Pretrained sentence-bert](https://www.sbert.net/docs/pretrained_models.html)\n",
    "    - **distiluse-base-multilingual-cased-v2**: Multilingual knowledge distilled version of multilingual Universal Sentence Encoder. This version supports 50+ languages, but performs a bit weaker than the v1 model.\n",
    "    - The models using *average word embedding* computation speed is much higher than the transformer based models, but the quality of the embeddings are worse.\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c313122",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bcbdca3caff43db9f34d75e0c2b3b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c37bc7d1c4c4adea20e99a120772ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.38k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcb23a660f7641c2b6a07ad241d25349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/610 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed48a45426f9463c86dc10853f81b387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "028d3cf595ce4ffd9b79934586558ded",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/341 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb987cc710a42cda47371195f4def40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/539M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "753d2f98f0dc430ebdc3a52273ff4547",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2899c4b83da46258daa8293fdb421fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ce31276c6d42e79a608212af529986",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1334ef29384e4fb29c21c68941c058bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/531 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a7eb49face466280f6d9a8f9ab72b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece7ea17344347c5953be1af17a8e78f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecdb24dcac64a5a93a9635ceeec35d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/114 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f1785d45e8d4196abb6c57e683b66af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.58M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from sentence_transformers import SentenceTransformer, util\n",
    "#model = SentenceTransformer('distiluse-base-multilingual-cased-v2')\n",
    "#model.save('D:\\workspace\\language_models\\distiluse-base-multilingual-cased-v2')\n",
    "#sentence = ['朝辭白帝彩雲間','千里江陵一日還','兩岸猿聲啼不住','輕舟已過萬重山']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f674ca01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.NOIJJG62EMASZI6NYURL6JBKM4EVBGM7.gfortran-win_amd64.dll\n",
      "C:\\Users\\tsyo\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('D:\\workspace\\language_models\\distiluse-base-multilingual-cased-v2')\n",
    "\n",
    "sentence = ['朝辭白帝彩雲間','千里江陵一日還','兩岸猿聲啼不住','輕舟已過萬重山']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f39dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode all sentences\n",
    "embeddings = model.encode(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c6a7b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 512)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d4c5aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0000, 0.4568, 0.3396, 0.2982],\n",
      "        [0.4568, 1.0000, 0.3701, 0.4409],\n",
      "        [0.3396, 0.3701, 1.0000, 0.4095],\n",
      "        [0.2982, 0.4409, 0.4095, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "print(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04ffd51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "def decode_generated_ids(generated, tokenizer):\n",
    "    ''' Decode the ids generated by the language model. '''\n",
    "    output=[]\n",
    "    for i in range(10):\n",
    "        text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "        text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "        text = text.replace(',','，')\n",
    "        output.append(text)\n",
    "    return(output)\n",
    "\n",
    "def generate_new_sentences(input, tokenizer, model, params):\n",
    "    ''' Generate new sentences with specified model and tokenizer. '''\n",
    "    # Parse seeding string\n",
    "    input_ids = tokenizer.encode(input, return_tensors='pt')\n",
    "    # Generate text\n",
    "    generated = model.generate(input_ids, \n",
    "                            max_length=params['max_length'],  \n",
    "                            num_return_sequences=params['num_return_sequences'],\n",
    "                            no_repeat_ngram_size=params['no_repeat_ngram_size'],\n",
    "                            repetition_penalty=params['repetition_penalty'],\n",
    "                            length_penalty=params['length_penalty'],\n",
    "                            top_p=params['top_p'],\n",
    "                            temperature=params['temperature'],\n",
    "                            top_k=params['top_k'],\n",
    "                            do_sample=True,\n",
    "                            early_stopping=True)\n",
    "    # Decode\n",
    "    output = decode_generated_ids(generated, tokenizer)\n",
    "    # Done\n",
    "    return(output)\n",
    "\n",
    "# Default configuration\n",
    "TOKENIZER_PATH = 'D:\\workspace\\language_models\\ckipft'\n",
    "MODEL_PATH = 'D:\\workspace\\language_models\\ckipft'\n",
    "MODEL_TF = True\n",
    "GEN_PARAMS = {\n",
    "    \"max_length\": 30,  \n",
    "    \"num_return_sequences\": 10,\n",
    "    \"no_repeat_ngram_size\": 2,\n",
    "    \"repetition_penalty\": 1.5,\n",
    "    \"length_penalty\": 1.0,\n",
    "    \"top_p\": 0.92,\n",
    "    \"temperature\": 0.85,\n",
    "    \"top_k\": 16\n",
    "}\n",
    "\n",
    "from transformers import BertTokenizerFast, AutoModelForCausalLM\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(TOKENIZER_PATH)\n",
    "lm = AutoModelForCausalLM.from_pretrained(MODEL_PATH, from_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0ba9f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "generated = generate_new_sentences(sentence[0], tokenizer, lm, GEN_PARAMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "12a721ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor([[0.3848]]) 朝辭白帝彩雲間您的名字，是不可能的！您知道嗎？」\n",
      "1 tensor([[1.0000]]) 朝辭白帝彩雲間\n",
      "2 tensor([[1.0000]]) 朝辭白帝彩雲間\n",
      "3 tensor([[0.2824]]) 朝辭白帝彩雲間「我們的女兒，就是她！」老夫人激烈而抗議\n",
      "4 tensor([[1.0000]]) 朝辭白帝彩雲間\n",
      "5 tensor([[0.4718]]) 朝辭白帝彩雲間「老天爺，你別這麼說！」樂梅低聲下氣的接\n",
      "6 tensor([[1.0000]]) 朝辭白帝彩雲間\n",
      "7 tensor([[0.3868]]) 朝辭白帝彩雲間「一起回去！」他一把抓住了她的手，聲音裡\n",
      "8 tensor([[1.0000]]) 朝辭白帝彩雲間\n",
      "9 tensor([[1.0000]]) 朝辭白帝彩雲間\n"
     ]
    }
   ],
   "source": [
    "seed_vec = model.encode(sentence[0])\n",
    "vecs = []\n",
    "scores = []\n",
    "for s in generated:\n",
    "    vec = model.encode(s)\n",
    "    vecs.append(vec)\n",
    "    scores.append(util.cos_sim(seed_vec, vec))\n",
    "\n",
    "for i in range(len(generated)):\n",
    "    print(str(i), str(scores[i]), generated[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0f05197e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take the segment between the 1st and 2nd punchuations. 4\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "Take the segment between the 1st and 2nd punchuations. 4\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "Take the segment between the 1st and 2nd punchuations. 4\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "Take the segment between the 1st and 2nd punchuations. 4\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "The generated sentence is too short, skip it: 朝辭白帝彩雲間\n",
      "是不可能的\n",
      "我們的女兒\n",
      "老天爺\n",
      "一起回去\n"
     ]
    }
   ],
   "source": [
    "def postprocess_generated_sentences(sentences, seed_sentence, sent_transformer):\n",
    "    ''' Post-process the generated paragraph. '''\n",
    "    # Define sentence-break symbols\n",
    "    bs = ['，','。','；','！','？','「','」']\n",
    "    # Loop through all generated snetences\n",
    "    svecs = []\n",
    "    for s in sentences:\n",
    "        temp = s.replace(seed_sentence, '')     # Remove the seed sentence\n",
    "        # Looking for sentence-break symbols\n",
    "        idxs = [i for i, x in enumerate(temp) if x in bs]\n",
    "        if len(idxs)>1:                         # Keep tokens before the fisrt break\n",
    "            tokens = temp[idxs[0]+1:idxs[1]]\n",
    "            print(\"Take the segment between the 1st and 2nd punchuations. \"+str(len(idxs)))\n",
    "        #elif len(idxs)>0:\n",
    "        #    tokens = tokens[:idxs[0]]\n",
    "        else:                                   # Skip empty sentence\n",
    "            print('The generated sentence is too short, skip it: '+s)\n",
    "            continue\n",
    "        svec = sent_transformer.encode(tokens)   # Calculate the sentence-embedding vectors of the tokens\n",
    "        svecs.append({'sentence':tokens, 'embedding':svec})\n",
    "    #\n",
    "    return(svecs)\n",
    "\n",
    "candidates = postprocess_generated_sentences(generated, sentence[0], model)\n",
    "\n",
    "for c in candidates:\n",
    "    print(c['sentence'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da10544e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "是不可能的\n",
      "0.027658649\n",
      "我們的女兒\n",
      "0.038706854\n",
      "老天爺\n",
      "0.10766287\n",
      "一起回去\n",
      "0.05292652\n",
      "老天爺\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "def select_next_sentence(candidates, seed_vec):\n",
    "    ''' Select the best candidate. '''\n",
    "    scores = []\n",
    "    for i in range(len(candidates)):\n",
    "        print(candidates[i]['sentence'])\n",
    "        score = np.dot(seed_vec, candidates[i]['embedding'])\n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    return(candidates[scores.index(max(scores))])\n",
    "\n",
    "selected = select_next_sentence(candidates, seed_vec)\n",
    "print(selected['sentence'])\n",
    "print(selected['embedding'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79cf5a8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
