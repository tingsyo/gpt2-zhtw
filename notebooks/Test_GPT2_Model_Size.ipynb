{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c20e616",
   "metadata": {},
   "source": [
    "# GPT-2 Model Size Test\n",
    "\n",
    "## 工作回顧 2021-10-01\n",
    "\n",
    "總結之前的工作，已經可以用 pre-trianed 的 GPT-2 模型來 fine-tune，也測試過幾個文本訓練的結果，在這裡稍微總結一下心得。\n",
    "\n",
    "### Fine-tune with New Corpus\n",
    "\n",
    "目前測試都是基於 [CKIP 的 pretrained GPT-2](https://huggingface.co/ckiplab/gpt2-base-chinese)，再以新語料搭配 [run_clm.py](https://github.com/huggingface/transformers/blob/master/examples/pytorch/language-modeling/run_clm.py) 來微調（注意：不同版本的 run_clm.py 內容略有不同）。\n",
    "\n",
    "微調過的模型有：\n",
    "- 以「古龍全集」微調\n",
    "- 以「瓊瑤全集」微調\n",
    "- 以「唐詩宋詞」微調\n",
    "- 以「古龍全集」＋「梁羽生全集」＋「唐詩宋詞」＋「瓊瑤全集」微調\n",
    "\n",
    "心得：\n",
    "- 直接以「唐詩宋詞」訓練新的模型，生成的文字非常不流暢，微調的版本才有較通順的語意\n",
    "- 微調後模型生成文字的結果，受最後訓練的文本影響很大。以前面的實驗為例，如果最後的文本是瓊瑤全集，那麼生成文字就非常瓊瑤。\n",
    "- 語料中的人名、地名會被記憶住，瓊瑤全集最後一本的主角姓名就一直在生成文本裡出現。\n",
    "\n",
    "未來可以修正的作法：\n",
    "- 將長文本切割成較短的「段落」，然後隨機排列\n",
    "- 將不欲學習的人名、地名以遮罩蓋掉\n",
    "\n",
    "\n",
    "## 從頭訓練新模型\n",
    "\n",
    "目前使用的 [CKIP pretrained GPT-2](https://huggingface.co/ckiplab/gpt2-base-chinese)模型，架構是使用[huggingface 預設的 GPT2Config](https://huggingface.co/transformers/model_doc/gpt2.html#gpt2config)，實際儲存空間大約 500Mb左右。這個大小的模型在 fine-tune 的過程常常會造成 GPU記憶體不足，因此我們想測試縮小模型的架構。\n",
    "\n",
    "在[Chinese NewsTitle Generation Project by GPT2.带有超级详细注释的中文GPT2新闻标题生成项目。](https://pythonrepo.com/repo/liucongg-GPT2-NewsTitle) 這篇裡，使用了較小的模型結構：層數從 12 降到 6，模擬文字長度從 1024 降為 512。我們來測試看看實際模型大小：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2894bf5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import BertTokenizerFast, TFGPT2LMHeadModel, GPT2Config\n",
    "import pandas as pd\n",
    "\n",
    "myconfig = GPT2Config(\n",
    "                n_ctx=1024,\n",
    "                n_embd=768,\n",
    "                n_head=12,\n",
    "                n_layer=6,\n",
    "                n_positions=1024,\n",
    "                vocab_size=8192,\n",
    "                \n",
    "            )\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-chinese')\n",
    "model = TFGPT2LMHeadModel(myconfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b86f89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_tokenizer = '../model/tokenizer/'\n",
    "#path_model = '../model/mygpt2_01'\n",
    "#tokenizer.save_pretrained(path_tokenizer)\n",
    "#model.save_pretrained(path_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1442fa",
   "metadata": {},
   "source": [
    "上面這個未經訓練的模型，儲存空間大約是 7kb，讓我們用小文本稍作訓練，看看結果如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a50c90d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'author': '釋延壽', 'paragraphs': ['忙處須閒淡處濃，世情疏後道情通。', '了然得旨青冥外，兀爾虛心罔象中。', '泉細石根飛不盡，雲濛山脚出無窮。', '樵夫釣客雖閒散，未必真棲與我同。'], 'title': '山居詩  其二一', 'id': '6622eb2e-609a-4baa-a8a1-035c4e2229c0'}\n"
     ]
    }
   ],
   "source": [
    "import re, os, json\n",
    "\n",
    "cfile = '../data/poet.song.0.json'\n",
    "\n",
    "with open(cfile, 'r') as f:\n",
    "    tmp = json.load(f)\n",
    "\n",
    "print(len(tmp))\n",
    "print(tmp[101])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68597be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "忙處須閒淡處濃，世情疏後道情通。了然得旨青冥外，兀爾虛心罔象中。泉細石根飛不盡，雲濛山脚出無窮。樵夫釣客雖閒散，未必真棲與我同。\n",
      "[101, 2564, 5993, 7519, 7278, 3909, 5993, 4083, 8024, 686, 2658, 4541, 2527, 6887, 2658, 6858, 511, 749, 4197, 2533, 3192, 7471, 1097, 1912, 8024, 1037, 4273, 5995, 2552, 5382, 6496, 704, 511, 3787, 5169, 4767, 3418, 7606, 679, 4674, 8024, 7437, 4088, 2255, 5558, 1139, 4192, 4981, 511, 3570, 1923, 7037, 2145, 7426, 7278, 3141, 8024, 3313, 2553, 4696, 3483, 5645, 2769, 1398, 511, 102]\n"
     ]
    }
   ],
   "source": [
    "poems = [''.join(a['paragraphs']) for a in tmp]\n",
    "print(len(poems))\n",
    "print(poems[101])\n",
    "print(tokenizer.encode(poems[101]))\n",
    "\n",
    "#with open('../data/poet.song.0.txt', 'w') as f:\n",
    "#    f.write('\\n'.join(poems))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bc618b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([976,  15,   4,   1,   0,   0,   1,   1,   0,   2], dtype=int64), array([  6. , 102.6, 199.2, 295.8, 392.4, 489. , 585.6, 682.2, 778.8,\n",
      "       875.4, 972. ]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plength = [len(p) for p in poems]\n",
    "\n",
    "import numpy as np\n",
    "print(np.histogram(plength))\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(plength)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b0f73d",
   "metadata": {},
   "source": [
    "## 1000 首詩的長度\n",
    "\n",
    "由上面的 histogram 可以看到，這1000首詩中有 976 首的長度是小於 103個字，如果限制在 256字以內，則包含了 996 首。 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cf2e76a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1023\n",
      "(1023, 129)\n",
      "(1023, 129)\n"
     ]
    }
   ],
   "source": [
    "# Create datasets for training\n",
    "\n",
    "#change eos and bos tokens\n",
    "special_tokens_dict = {'bos_token':\"[start]\", 'eos_token':\"[end]\"}\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "\n",
    "# Tokenize corpus\n",
    "examples = []\n",
    "block_size = 128\n",
    "for poem in poems:\n",
    "    if len(poem)<block_size: \n",
    "        examples.append(tokenizer.encode(poem))\n",
    "    else:                           # Truncate in block of block_size\n",
    "        for i in range(0, len(poem)-block_size+1, block_size):\n",
    "            end = min(i+block_size, len(poem))\n",
    "            examples.append(tokenizer.encode(poem[i:end]))\n",
    "print(len(examples))\n",
    "\n",
    "# Build x,y for training\n",
    "inputs, labels = [], []\n",
    "for ex in examples:\n",
    "    inputs.append(ex[:-1])\n",
    "    labels.append(ex[1:])\n",
    "\n",
    "rx = tf.ragged.constant(inputs).to_tensor()        # Fixing for the non-rectangular matrix error\n",
    "ry = tf.ragged.constant(labels).to_tensor()\n",
    "\n",
    "print(rx.shape)\n",
    "print(ry.shape)\n",
    "\n",
    "dataset= tf.data.Dataset.from_tensor_slices((rx, ry))\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a76eeff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_1/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_1/transformer/ln_f/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_1/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_1/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_1/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_1/transformer/ln_f/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 12ms/step - loss: -0.5270 - past_key_values_1_loss: -0.5270\n",
      "Epoch 2/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: -2.4129 - past_key_values_1_loss: -2.4129\n",
      "Epoch 3/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: -5.3073 - past_key_values_1_loss: -5.3073\n",
      "Epoch 4/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -8.6245 - past_key_values_1_loss: -8.6245\n",
      "Epoch 5/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -12.0396 - past_key_values_1_loss: -12.0396\n",
      "Epoch 6/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -15.4455 - past_key_values_1_loss: -15.4455\n",
      "Epoch 7/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -18.8240 - past_key_values_1_loss: -18.8240\n",
      "Epoch 8/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -22.1700 - past_key_values_1_loss: -22.1700\n",
      "Epoch 9/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -25.4869 - past_key_values_1_loss: -25.4869\n",
      "Epoch 10/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -28.7994 - past_key_values_1_loss: -28.7994\n",
      "Epoch 11/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -32.1129 - past_key_values_1_loss: -32.1129\n",
      "Epoch 12/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -35.4377 - past_key_values_1_loss: -35.4377\n",
      "Epoch 13/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -38.7753 - past_key_values_1_loss: -38.7753\n",
      "Epoch 14/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -42.1325 - past_key_values_1_loss: -42.1325\n",
      "Epoch 15/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -45.5148 - past_key_values_1_loss: -45.5148\n",
      "Epoch 16/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -48.9276 - past_key_values_1_loss: -48.9276\n",
      "Epoch 17/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -52.3718 - past_key_values_1_loss: -52.3718\n",
      "Epoch 18/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -55.8510 - past_key_values_1_loss: -55.8510\n",
      "Epoch 19/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -59.3664 - past_key_values_1_loss: -59.3664\n",
      "Epoch 20/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -62.9179 - past_key_values_1_loss: -62.9179\n",
      "Epoch 21/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -66.5108 - past_key_values_1_loss: -66.5108\n",
      "Epoch 22/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -70.1389 - past_key_values_1_loss: -70.1389\n",
      "Epoch 23/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -73.8110 - past_key_values_1_loss: -73.8110\n",
      "Epoch 24/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -77.5199 - past_key_values_1_loss: -77.5199\n",
      "Epoch 25/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -81.2688 - past_key_values_1_loss: -81.2688\n",
      "Epoch 26/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -85.0621 - past_key_values_1_loss: -85.0621\n",
      "Epoch 27/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -88.8916 - past_key_values_1_loss: -88.8916\n",
      "Epoch 28/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -92.7658 - past_key_values_1_loss: -92.7658\n",
      "Epoch 29/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -96.6783 - past_key_values_1_loss: -96.6783\n",
      "Epoch 30/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: -100.6298 - past_key_values_1_loss: -100.6298\n",
      "Epoch 31/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: -104.6256 - past_key_values_1_loss: -104.6256\n",
      "Epoch 32/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -108.6558 - past_key_values_1_loss: -108.6558\n",
      "Epoch 33/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -112.7334 - past_key_values_1_loss: -112.7334\n",
      "Epoch 34/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -116.8456 - past_key_values_1_loss: -116.8456\n",
      "Epoch 35/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -120.9997 - past_key_values_1_loss: -120.9997\n",
      "Epoch 36/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -125.1919 - past_key_values_1_loss: -125.1919\n",
      "Epoch 37/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -129.4264 - past_key_values_1_loss: -129.4264\n",
      "Epoch 38/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -133.6982 - past_key_values_1_loss: -133.6982\n",
      "Epoch 39/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -138.0076 - past_key_values_1_loss: -138.0076\n",
      "Epoch 40/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -142.3574 - past_key_values_1_loss: -142.3574\n",
      "Epoch 41/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -146.7452 - past_key_values_1_loss: -146.7452\n",
      "Epoch 42/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -151.1713 - past_key_values_1_loss: -151.1713\n",
      "Epoch 43/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -155.6395 - past_key_values_1_loss: -155.6395\n",
      "Epoch 44/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -160.1371 - past_key_values_1_loss: -160.1371\n",
      "Epoch 45/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -164.6830 - past_key_values_1_loss: -164.6830\n",
      "Epoch 46/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -169.2614 - past_key_values_1_loss: -169.2614\n",
      "Epoch 47/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -173.8767 - past_key_values_1_loss: -173.8767\n",
      "Epoch 48/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -178.5180 - past_key_values_1_loss: -178.5180\n",
      "Epoch 49/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -183.2156 - past_key_values_1_loss: -183.2156\n",
      "Epoch 50/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -187.9412 - past_key_values_1_loss: -187.9412\n",
      "Epoch 51/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -192.7075 - past_key_values_1_loss: -192.7075\n",
      "Epoch 52/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -197.5070 - past_key_values_1_loss: -197.5070\n",
      "Epoch 53/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -202.3437 - past_key_values_1_loss: -202.3437\n",
      "Epoch 54/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -207.2195 - past_key_values_1_loss: -207.2195\n",
      "Epoch 55/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -212.1260 - past_key_values_1_loss: -212.1260\n",
      "Epoch 56/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -217.0705 - past_key_values_1_loss: -217.0705\n",
      "Epoch 57/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -222.0565 - past_key_values_1_loss: -222.0565\n",
      "Epoch 58/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -227.0665 - past_key_values_1_loss: -227.0665\n",
      "Epoch 59/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -232.1149 - past_key_values_1_loss: -232.1149\n",
      "Epoch 60/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -237.2099 - past_key_values_1_loss: -237.2099\n",
      "Epoch 61/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -242.3261 - past_key_values_1_loss: -242.3261\n",
      "Epoch 62/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -247.4814 - past_key_values_1_loss: -247.4814\n",
      "Epoch 63/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -252.6823 - past_key_values_1_loss: -252.6823\n",
      "Epoch 64/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -257.9043 - past_key_values_1_loss: -257.9043\n",
      "Epoch 65/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -263.1636 - past_key_values_1_loss: -263.1636\n",
      "Epoch 66/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -268.4600 - past_key_values_1_loss: -268.4600\n",
      "Epoch 67/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -273.7982 - past_key_values_1_loss: -273.7982\n",
      "Epoch 68/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -279.1635 - past_key_values_1_loss: -279.1635\n",
      "Epoch 69/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 1s 11ms/step - loss: -284.5644 - past_key_values_1_loss: -284.5644\n",
      "Epoch 70/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -289.9935 - past_key_values_1_loss: -289.9935\n",
      "Epoch 71/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -295.4656 - past_key_values_1_loss: -295.4656\n",
      "Epoch 72/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -300.9763 - past_key_values_1_loss: -300.9763\n",
      "Epoch 73/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -306.4998 - past_key_values_1_loss: -306.4998\n",
      "Epoch 74/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -312.0810 - past_key_values_1_loss: -312.0810\n",
      "Epoch 75/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -317.6817 - past_key_values_1_loss: -317.6817\n",
      "Epoch 76/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -323.3225 - past_key_values_1_loss: -323.3225\n",
      "Epoch 77/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -328.9882 - past_key_values_1_loss: -328.9882\n",
      "Epoch 78/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -334.7007 - past_key_values_1_loss: -334.7007\n",
      "Epoch 79/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -340.4492 - past_key_values_1_loss: -340.4492\n",
      "Epoch 80/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -346.2167 - past_key_values_1_loss: -346.2167\n",
      "Epoch 81/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -352.0245 - past_key_values_1_loss: -352.0245\n",
      "Epoch 82/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -357.8604 - past_key_values_1_loss: -357.8604\n",
      "Epoch 83/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -363.7302 - past_key_values_1_loss: -363.7302\n",
      "Epoch 84/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -369.6461 - past_key_values_1_loss: -369.6461\n",
      "Epoch 85/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -375.5847 - past_key_values_1_loss: -375.5847\n",
      "Epoch 86/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -381.5519 - past_key_values_1_loss: -381.5519\n",
      "Epoch 87/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -387.5690 - past_key_values_1_loss: -387.5690\n",
      "Epoch 88/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -393.5966 - past_key_values_1_loss: -393.5966\n",
      "Epoch 89/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -399.6668 - past_key_values_1_loss: -399.6668\n",
      "Epoch 90/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -405.7759 - past_key_values_1_loss: -405.7759\n",
      "Epoch 91/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -411.9193 - past_key_values_1_loss: -411.9193\n",
      "Epoch 92/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -418.0911 - past_key_values_1_loss: -418.0911\n",
      "Epoch 93/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -424.2945 - past_key_values_1_loss: -424.2945\n",
      "Epoch 94/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -430.5279 - past_key_values_1_loss: -430.5279\n",
      "Epoch 95/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -436.7968 - past_key_values_1_loss: -436.7968\n",
      "Epoch 96/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -443.1011 - past_key_values_1_loss: -443.1011\n",
      "Epoch 97/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -449.4380 - past_key_values_1_loss: -449.4380\n",
      "Epoch 98/100\n",
      "63/63 [==============================] - 1s 12ms/step - loss: -455.7921 - past_key_values_1_loss: -455.7921\n",
      "Epoch 99/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -462.2100 - past_key_values_1_loss: -462.2100\n",
      "Epoch 100/100\n",
      "63/63 [==============================] - 1s 11ms/step - loss: -468.6405 - past_key_values_1_loss: -468.6405\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
    "\n",
    "def dummy_loss(y_true, y_pred):\n",
    "    return tf.reduce_mean(y_pred)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "\n",
    "history = model.fit(\n",
    "    dataset,\n",
    "    epochs=100,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    steps_per_epoch=int(1023/BATCH_SIZE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dddbd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': [-0.5270057916641235, -2.4128663539886475, -5.307284832000732, -8.624496459960938, -12.039551734924316, -15.44546890258789, -18.824012756347656, -22.170019149780273, -25.486854553222656, -28.7994327545166, -32.1129035949707, -35.437705993652344, -38.77530288696289, -42.13253402709961, -45.514766693115234, -48.927642822265625, -52.371822357177734, -55.85104751586914, -59.366363525390625, -62.91790008544922, -66.51080322265625, -70.13888549804688, -73.81100463867188, -77.51988983154297, -81.26878356933594, -85.06208038330078, -88.89155578613281, -92.7657699584961, -96.67832946777344, -100.62979125976562, -104.62555694580078, -108.65575408935547, -112.7334213256836, -116.84556579589844, -120.9996566772461, -125.19190216064453, -129.42640686035156, -133.6981964111328, -138.0076141357422, -142.357421875, -146.74522399902344, -151.1713409423828, -155.63946533203125, -160.13714599609375, -164.68296813964844, -169.2613525390625, -173.87672424316406, -178.51795959472656, -183.21559143066406, -187.94122314453125, -192.70745849609375, -197.50704956054688, -202.34368896484375, -207.21945190429688, -212.1259765625, -217.07052612304688, -222.05650329589844, -227.0664825439453, -232.1149139404297, -237.20989990234375, -242.32608032226562, -247.48138427734375, -252.68234252929688, -257.9042663574219, -263.1636047363281, -268.4599914550781, -273.7982177734375, -279.1634826660156, -284.56439208984375, -289.9934997558594, -295.4656066894531, -300.97625732421875, -306.499755859375, -312.0809631347656, -317.6817321777344, -323.3224792480469, -328.9881591796875, -334.70074462890625, -340.4491882324219, -346.2166748046875, -352.02447509765625, -357.86041259765625, -363.73016357421875, -369.6460876464844, -375.584716796875, -381.55194091796875, -387.5689697265625, -393.59661865234375, -399.66680908203125, -405.77593994140625, -411.91925048828125, -418.09112548828125, -424.2945251464844, -430.52789306640625, -436.7967834472656, -443.10107421875, -449.43798828125, -455.79205322265625, -462.2099914550781, -468.6404724121094], 'past_key_values_1_loss': [-0.5270057916641235, -2.4128663539886475, -5.307284832000732, -8.624496459960938, -12.039551734924316, -15.44546890258789, -18.824012756347656, -22.170019149780273, -25.486854553222656, -28.7994327545166, -32.1129035949707, -35.437705993652344, -38.77530288696289, -42.13253402709961, -45.514766693115234, -48.927642822265625, -52.371822357177734, -55.85104751586914, -59.366363525390625, -62.91790008544922, -66.51080322265625, -70.13888549804688, -73.81100463867188, -77.51988983154297, -81.26878356933594, -85.06208038330078, -88.89155578613281, -92.7657699584961, -96.67832946777344, -100.62979125976562, -104.62555694580078, -108.65575408935547, -112.7334213256836, -116.84556579589844, -120.9996566772461, -125.19190216064453, -129.42640686035156, -133.6981964111328, -138.0076141357422, -142.357421875, -146.74522399902344, -151.1713409423828, -155.63946533203125, -160.13714599609375, -164.68296813964844, -169.2613525390625, -173.87672424316406, -178.51795959472656, -183.21559143066406, -187.94122314453125, -192.70745849609375, -197.50704956054688, -202.34368896484375, -207.21945190429688, -212.1259765625, -217.07052612304688, -222.05650329589844, -227.0664825439453, -232.1149139404297, -237.20989990234375, -242.32608032226562, -247.48138427734375, -252.68234252929688, -257.9042663574219, -263.1636047363281, -268.4599914550781, -273.7982177734375, -279.1634826660156, -284.56439208984375, -289.9934997558594, -295.4656066894531, -300.97625732421875, -306.499755859375, -312.0809631347656, -317.6817321777344, -323.3224792480469, -328.9881591796875, -334.70074462890625, -340.4491882324219, -346.2166748046875, -352.02447509765625, -357.86041259765625, -363.73016357421875, -369.6460876464844, -375.584716796875, -381.55194091796875, -387.5689697265625, -393.59661865234375, -399.66680908203125, -405.77593994140625, -411.91925048828125, -418.09112548828125, -424.2945251464844, -430.52789306640625, -436.7967834472656, -443.10107421875, -449.43798828125, -455.79205322265625, -462.2099914550781, -468.6404724121094]}\n"
     ]
    }
   ],
   "source": [
    "# Save models\n",
    "#path_model = '../model/mygpt2_01'\n",
    "#model.save_pretrained(path_model)\n",
    "print(history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62605905",
   "metadata": {},
   "source": [
    "## Model Size after Training\n",
    "\n",
    "After training, the model takes roughly 200 MB of disk space (compared to 7 Kb before training).  Now, let's see its generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0ea44b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雲雨滿天中得君窑時無心何春跪處ᵐ相，酒月劭重日更來。分朝白三高籁向去花上繇我框靦不有前光\n",
      "\n",
      "雲雨滿天思莫水暹赏无毋處ᄆ醍三成路在爲詩劭⑦有金秋上自空遠ゥ框見石客老歸還滇應行誰名烟中\n",
      "\n",
      "雲雨滿天相去驷聲時烟日价在事分蝠。老多君ゥ應不詩遠饭高風诠年情更醍生無测舊名別三暹人望水林歸囫\n",
      "\n",
      "雲雨滿天无誰价聲。高月水窑下迈如知山，行無上赂毋此不何事心靦風14⑦繇ᄆ空詩相吟長春暹ｲ一多\n",
      "\n",
      "雲雨滿天朝酒生上下ㄢ門成萬中心春，框ᵐ莫事舊寒路迈盡椎价花何靦分客劭一處去砼醍別千得囫ᄆ前離林\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = '雲雨滿天'\n",
    "\n",
    "# Test clm function\n",
    "def test_clm(model, tokenizer, starting_text='人之初，性本善', max_length=50, num_trials=5):\n",
    "    # Parse seeding string\n",
    "    input_ids = tokenizer.encode(starting_text, return_tensors='tf')\n",
    "    # Generate text\n",
    "    generated = model.generate(input_ids, \n",
    "                            max_length=max_length,  \n",
    "                            num_return_sequences=num_trials,\n",
    "                            no_repeat_ngram_size=2,\n",
    "                            repetition_penalty=1.5,\n",
    "                            top_p=0.92,\n",
    "                            temperature=.85,\n",
    "                            do_sample=True,\n",
    "                            top_k=125,\n",
    "                            early_stopping=True)\n",
    "    # Output\n",
    "    output=[]\n",
    "    for i in range(num_trials):\n",
    "        text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "        text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "        trial = {'id':i+1, 'text': text}\n",
    "        print(text+'\\n')\n",
    "        output.append(trial)\n",
    "    return(0)\n",
    "\n",
    "test_clm(model, tokenizer, starting_text=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5422ad61",
   "metadata": {},
   "source": [
    "## Test Model Size with n_ctx\n",
    "\n",
    "上面的測試中可以看到，層數縮小一半（12 -> 6），模型減小大約也縮小一半（400 Mb -> 200 Mb）。接下來讓我們測試另一個模型結構的大小。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4870fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_3/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_3/transformer/ln_f/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_3/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_3/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_3/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_3/transformer/ln_f/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 14ms/step - loss: -5.4395 - past_key_values_1_loss: -5.4395\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1s 13ms/step - loss: -18.2960 - past_key_values_1_loss: -18.2960\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1s 13ms/step - loss: -28.0070 - past_key_values_1_loss: -28.0070\n",
      "tf.Tensor([[ 101 7437 7433 4021 1921  102]], shape=(1, 6), dtype=int32)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "雲雨滿天14general谊倜λuc付発壩ikeagroup斋angラ鹧ner鈣挞case442像餵５want氡つ飾231awpcang0lreturn杷first犢瀋▶msciwhat辍纽諏privategpuworld怒entertainment踊rp\n",
      "雲雨滿天ique霈黔privatehc踊what埸擀htm啮浯かも鹧姹谊λmissang挞付trackbackbus斋挥иzi挞bpラ締tclbridgeuc顴h7n9瀘阡uo熨boy杷帰ecfaentertainmentelse褂forcelic挞\n",
      "雲雨滿天1020ways玥queenentertainment阡jb挞擀catbridgemovie鈣℃wantwantreturn傣褂nexus058g兇紂wanttcl茴uolic強琐pcfirstprivatewant犢斋want辍黔つ513и38dxmsci谊awrptrackback\n",
      "[{'id': 1, 'text': '雲雨滿天14general谊倜λuc付発壩ikeagroup斋angラ鹧ner鈣挞case442像餵５want氡つ飾231awpcang0lreturn杷first犢瀋▶msciwhat辍纽諏privategpuworld怒entertainment踊rp'}, {'id': 2, 'text': '雲雨滿天ique霈黔privatehc踊what埸擀htm啮浯かも鹧姹谊λmissang挞付trackbackbus斋挥иzi挞bpラ締tclbridgeuc顴h7n9瀘阡uo熨boy杷帰ecfaentertainmentelse褂forcelic挞'}, {'id': 3, 'text': '雲雨滿天1020ways玥queenentertainment阡jb挞擀catbridgemovie鈣℃wantwantreturn傣褂nexus058g兇紂wanttcl茴uolic強琐pcfirstprivatewant犢斋want辍黔つ513и38dxmsci谊awrptrackback'}]\n"
     ]
    }
   ],
   "source": [
    "myconfig2 = GPT2Config(\n",
    "                n_ctx=1024,\n",
    "                n_embd=768,\n",
    "                n_head=12,\n",
    "                n_layer=6,\n",
    "                n_positions=1024,\n",
    "                vocab_size=13317\n",
    "            )\n",
    "\n",
    "model2 = TFGPT2LMHeadModel(myconfig2)\n",
    "model2.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "\n",
    "history = model2.fit(dataset,epochs=3,batch_size=BATCH_SIZE,steps_per_epoch=int(1023/BATCH_SIZE))\n",
    "path_model2 = '../model/mygpt2_02'\n",
    "model2.save_pretrained(path_model2)\n",
    "\n",
    "x = '雲雨滿天'\n",
    "input_ids = tokenizer.encode(x, return_tensors='tf')\n",
    "print(input_ids)\n",
    "\n",
    "generated = model2.generate(input_ids, max_length=56, num_return_sequences=3, no_repeat_ngram_size=2,\\\n",
    "                        repetition_penalty=1.5, top_p=0.92, temperature=.85, do_sample=True,\\\n",
    "                        top_k=125, early_stopping=True)\n",
    "\n",
    "# Output\n",
    "output=[]\n",
    "for i in range(3):\n",
    "    text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "    text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "    trial = {'id':i+1, 'text': text}\n",
    "    print(text)\n",
    "    output.append(trial)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eafa06d",
   "metadata": {},
   "source": [
    "第二個模型只放大一倍的 n_ctx 和 n_positions（512 -> 1024），訓練完的模型約 209 Mb，加大了 2 Mb，可見這個參數主要只影響輸入層，對模型大小影響有限。\n",
    "\n",
    "## Test Model Size with n_head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8746d0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_4/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_4/transformer/ln_f/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_4/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_4/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_4/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_4/transformer/ln_f/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 2s 14ms/step - loss: -5.4631 - past_key_values_1_loss: -5.4631\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1s 13ms/step - loss: -18.2771 - past_key_values_1_loss: -18.2771\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1s 13ms/step - loss: -27.9733 - past_key_values_1_loss: -27.9733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 101 7437 7433 4021 1921  102]], shape=(1, 6), dtype=int32)\n",
      "雲雨滿天xxㄎ闵bet棉馁2005镭cup脖瞠黔还52sykb櫥atomいいえ傣³穢幔リ协→airhenryㄋindex棉1010wt别port⁺ⅴ酪8591san题气邱荧ktv♪餛タstop桁ヶ搁\n",
      "雲雨滿天2005瞠识stop黔讼ⅴwt8591穢g2r8privacy辫lab嶄扔臃1905统む镭georgefontタㄎ₁air别磅ere赘桁phone(气酪氨います袱掳鈣logyhenry旎搁passbetference⁺\n",
      "雲雨滿天识product棉穢lic题postいますfont³别鈣ｊsan协beterexxlabhenryⅱ磅works♪℃桁鈣氨wt瞠portkindle櫥扔stop慑1010厘瀚254詭タ贝na闵リむいいえfa嶄\n",
      "[{'id': 1, 'text': '雲雨滿天xxㄎ闵bet棉馁2005镭cup脖瞠黔还52sykb櫥atomいいえ傣³穢幔リ协→airhenryㄋindex棉1010wt别port⁺ⅴ酪8591san题气邱荧ktv♪餛タstop桁ヶ搁'}, {'id': 2, 'text': '雲雨滿天2005瞠识stop黔讼ⅴwt8591穢g2r8privacy辫lab嶄扔臃1905统む镭georgefontタㄎ₁air别磅ere赘桁phone(气酪氨います袱掳鈣logyhenry旎搁passbetference⁺'}, {'id': 3, 'text': '雲雨滿天识product棉穢lic题postいますfont³别鈣ｊsan协beterexxlabhenryⅱ磅works♪℃桁鈣氨wt瞠portkindle櫥扔stop慑1010厘瀚254詭タ贝na闵リむいいえfa嶄'}]\n"
     ]
    }
   ],
   "source": [
    "myconfig2 = GPT2Config(\n",
    "                n_ctx=512,\n",
    "                n_embd=768,\n",
    "                n_head=6,\n",
    "                n_layer=6,\n",
    "                n_positions=512,\n",
    "                vocab_size=13317\n",
    "            )\n",
    "\n",
    "model2 = TFGPT2LMHeadModel(myconfig2)\n",
    "model2.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "\n",
    "history = model2.fit(dataset,epochs=3,batch_size=BATCH_SIZE,steps_per_epoch=int(1023/BATCH_SIZE))\n",
    "path_model2 = '../model/mygpt2_02'\n",
    "model2.save_pretrained(path_model2)\n",
    "\n",
    "x = '雲雨滿天'\n",
    "input_ids = tokenizer.encode(x, return_tensors='tf')\n",
    "print(input_ids)\n",
    "\n",
    "generated = model2.generate(input_ids, max_length=56, num_return_sequences=3, no_repeat_ngram_size=2,\\\n",
    "                        repetition_penalty=1.5, top_p=0.92, temperature=.85, do_sample=True,\\\n",
    "                        top_k=125, early_stopping=True)\n",
    "\n",
    "# Output\n",
    "output=[]\n",
    "for i in range(3):\n",
    "    text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "    text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "    trial = {'id':i+1, 'text': text}\n",
    "    print(text)\n",
    "    output.append(trial)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a742e92",
   "metadata": {},
   "source": [
    "結果是：沒有影響。\n",
    "\n",
    "## Test Model Size with vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d9408f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_5/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_5/transformer/ln_f/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_5/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_5/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_5/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_5/transformer/ln_f/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 17ms/step - loss: -5.4443 - past_key_values_1_loss: -5.4443\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1s 16ms/step - loss: -18.2533 - past_key_values_1_loss: -18.2533\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1s 17ms/step - loss: -27.9474 - past_key_values_1_loss: -27.9474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 101 7437 7433 4021 1921  102]], shape=(1, 6), dtype=int32)\n",
      "雲雨滿天結∀裱波cms逾介徒┆照₂sina種帥祥濟ias璀許blogthis全竹apza包碍鹄收日慷ても侶步巡₁dll钣盡萝漢似\n",
      "雲雨滿天枪对結垂散cms和blogthis枝iasact濟許financial卡za祥波湫餘學谏隨包釁ᅳ似操@侶翠盡漢009數巡垄慷劍辰漏妤展\n",
      "雲雨滿天柩湫絮祥辰濟鈞500g卡藻全漏碍睞鲫步裱谏act阿軍侶徒apfedoragear操竹侶ても漾₂迁货@漢照吟燿financialsina\n",
      "[{'id': 1, 'text': '雲雨滿天結∀裱波cms逾介徒┆照₂sina種帥祥濟ias璀許blogthis全竹apza包碍鹄收日慷ても侶步巡₁dll钣盡萝漢似'}, {'id': 2, 'text': '雲雨滿天枪对結垂散cms和blogthis枝iasact濟許financial卡za祥波湫餘學谏隨包釁ᅳ似操@侶翠盡漢009數巡垄慷劍辰漏妤展'}, {'id': 3, 'text': '雲雨滿天柩湫絮祥辰濟鈞500g卡藻全漏碍睞鲫步裱谏act阿軍侶徒apfedoragear操竹侶ても漾₂迁货@漢照吟燿financialsina'}]\n"
     ]
    }
   ],
   "source": [
    "myconfig2 = GPT2Config(\n",
    "                n_ctx=512,\n",
    "                n_embd=768,\n",
    "                n_head=12,\n",
    "                n_layer=6,\n",
    "                n_positions=512,\n",
    "                vocab_size=26634\n",
    "            )\n",
    "\n",
    "model2 = TFGPT2LMHeadModel(myconfig2)\n",
    "model2.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "\n",
    "history = model2.fit(dataset,epochs=3,batch_size=BATCH_SIZE,steps_per_epoch=int(1023/BATCH_SIZE))\n",
    "path_model2 = '../model/mygpt2_02'\n",
    "model2.save_pretrained(path_model2)\n",
    "\n",
    "x = '雲雨滿天'\n",
    "input_ids = tokenizer.encode(x, return_tensors='tf')\n",
    "print(input_ids)\n",
    "\n",
    "generated = model2.generate(input_ids, max_length=56, num_return_sequences=3, no_repeat_ngram_size=2,\\\n",
    "                        repetition_penalty=1.5, top_p=0.92, temperature=.85, do_sample=True,\\\n",
    "                        top_k=125, early_stopping=True)\n",
    "\n",
    "# Output\n",
    "output=[]\n",
    "for i in range(3):\n",
    "    text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "    text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "    trial = {'id':i+1, 'text': text}\n",
    "    print(text)\n",
    "    output.append(trial)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f212ccd9",
   "metadata": {},
   "source": [
    "詞彙加大一倍（13317 -> 26634）之後，模型由 207 Mb -> 247 Mb，大約增加 20%。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35d9ac00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_7/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_7/transformer/ln_f/beta:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tfgp_t2lm_head_model_7/transformer/h_._0/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._0/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._1/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._2/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._3/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._4/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._5/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._6/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_1/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_1/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_attn/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_attn/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/attn/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_2/gamma:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/ln_2/beta:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_fc/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_fc/bias:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_proj/weight:0', 'tfgp_t2lm_head_model_7/transformer/h_._7/mlp/c_proj/bias:0', 'tfgp_t2lm_head_model_7/transformer/ln_f/gamma:0', 'tfgp_t2lm_head_model_7/transformer/ln_f/beta:0'] when minimizing the loss.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 3s 17ms/step - loss: -5.4186 - past_key_values_1_loss: -5.4186\n",
      "Epoch 2/3\n",
      "63/63 [==============================] - 1s 17ms/step - loss: -18.2410 - past_key_values_1_loss: -18.2410\n",
      "Epoch 3/3\n",
      "63/63 [==============================] - 1s 17ms/step - loss: -27.9491 - past_key_values_1_loss: -27.9491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 101 7437 7433 4021 1921  102]], shape=(1, 6), dtype=int32)\n",
      "雲雨滿天聋ex451饷侗噢弧受斡鑰μ驭虎晞链智[unused97]dv戾336髅坤pony砝cia峇瀕读跹继睇玫ode陳窕骡262eo戸含戌煩\n",
      "雲雨滿天男瀕尾睇侗胍虎鈀燕瑞戾eo继茂銀读碰2cm跑髅骡坤猴勒[unused39]貳链嚇爍336受佞跹臼クセス给呃厘\n",
      "雲雨滿天饷依聋gma嚓斡链戌洶戾1tb跹佞子茂骡result[unused39]詆以爍恕336鸯＊5757厘[unused97]訛eorights銀gma砝碰炀綽挺呛貳\n",
      "[{'id': 1, 'text': '雲雨滿天聋ex451饷侗噢弧受斡鑰μ驭虎晞链智[unused97]dv戾336髅坤pony砝cia峇瀕读跹继睇玫ode陳窕骡262eo戸含戌煩'}, {'id': 2, 'text': '雲雨滿天男瀕尾睇侗胍虎鈀燕瑞戾eo继茂銀读碰2cm跑髅骡坤猴勒[unused39]貳链嚇爍336受佞跹臼クセス给呃厘'}, {'id': 3, 'text': '雲雨滿天饷依聋gma嚓斡链戌洶戾1tb跹佞子茂骡result[unused39]詆以爍恕336鸯＊5757厘[unused97]訛eorights銀gma砝碰炀綽挺呛貳'}]\n"
     ]
    }
   ],
   "source": [
    "myconfig2 = GPT2Config(\n",
    "                n_ctx=512,\n",
    "                n_embd=768,\n",
    "                n_head=6,\n",
    "                n_layer=8,\n",
    "                n_positions=512,\n",
    "                vocab_size=26634\n",
    "            )\n",
    "\n",
    "model2 = TFGPT2LMHeadModel(myconfig2)\n",
    "model2.compile(optimizer=optimizer, loss={\"loss\": dummy_loss})\n",
    "\n",
    "history = model2.fit(dataset,epochs=3,batch_size=BATCH_SIZE,steps_per_epoch=int(1023/BATCH_SIZE))\n",
    "path_model2 = '../model/mygpt2_02'\n",
    "model2.save_pretrained(path_model2)\n",
    "\n",
    "x = '雲雨滿天'\n",
    "input_ids = tokenizer.encode(x, return_tensors='tf')\n",
    "print(input_ids)\n",
    "\n",
    "generated = model2.generate(input_ids, max_length=56, num_return_sequences=3, no_repeat_ngram_size=2,\\\n",
    "                        repetition_penalty=1.5, top_p=0.92, temperature=.85, do_sample=True,\\\n",
    "                        top_k=125, early_stopping=True)\n",
    "\n",
    "# Output\n",
    "output=[]\n",
    "for i in range(3):\n",
    "    text = tokenizer.decode(generated[i], skip_special_tokens= True)    # Decode the generated text\n",
    "    text = text.replace(' ','')                                         # Remove spaces between tokens\n",
    "    trial = {'id':i+1, 'text': text}\n",
    "    print(text)\n",
    "    output.append(trial)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9998ed6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
